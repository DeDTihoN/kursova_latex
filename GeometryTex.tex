% !TeX program = xelatex
\documentclass[a4paper,14pt]{extarticle} % Использование extarticle для 14pt шрифта
\usepackage{fontspec} % Для использования системных шрифтов	
\usepackage{polyglossia} % Для многоязыковой поддержки
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{indentfirst} % Для отступа в первом абзаце
\setlength{\parindent}{1.25cm} % Установка отступа в 1.25 см
\setlength{\parskip}{0em} % Установка межабзацного интервала в 0

\newfontfamily\cyrillicfonttt{Courier New}

\lstset{ 
    language=[Sharp]C,              % Язык кода - C#
    basicstyle=\ttfamily\footnotesize, % Основной стиль шрифта
    keywordstyle=\color{blue},       % Цвет ключевых слов
    commentstyle=\color{green},      % Цвет комментариев
    stringstyle=\color{red},         % Цвет строк
    numbers=left,                   % Номера строк слева
    numberstyle=\tiny\color{gray},  % Стиль номеров строк
    stepnumber=1,                   % Нумерация каждой строки
    numbersep=5pt,                  % Расстояние между номерами строк и кодом
    showspaces=false,               % Показывать пробелы
    showstringspaces=false,         % Показывать пробелы внутри строк
    showtabs=false,                 % Показывать табуляцию
    frame=single,                   % Рамка вокруг кода
    tabsize=4,                      % Размер табуляции
    captionpos=b,                   % Позиция заголовка (b - снизу)
    breaklines=true,                % Перенос строк
    breakatwhitespace=false,        % Переносить строки только на пробелах
    title=\lstname,                 % Показывать название файла
    escapeinside={\%*}{*)},         % ЛаТеХ команды внутри кода
    morekeywords={var, get, set}    % Дополнительные ключевые слова
}

\renewcommand{\lstlistingname}{Лістинг} % Зміна підпису лістингу на українську мову

\setmainlanguage{ukrainian} % Основной язык документа
\setotherlanguage{english} % Дополнительный язык документа
\setmainfont{Times New Roman} % Установка шрифта Times New Roman
\usepackage{geometry} % Пакет для настройки полей страницы
\geometry{
    left=3cm,
    right=1.5cm,
    top=2cm,
    bottom=2cm
}

\usepackage{titlesec} % Пакет для настройки заголовков
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

\usepackage{setspace} % Пакет для настройки межстрочного интервала
\onehalfspacing % Установка полуторного интервала

\usepackage{tocloft} % Пакет для настройки оглавления
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} % Добавление точек к оглавлению

\usepackage{fancyhdr} % Пакет для настройки колонтитулов
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt} % Убирает линию вверху страницы
\renewcommand{\footrulewidth}{0pt} % Убирает линию внизу страницы

\usepackage{graphicx}
\usepackage{caption} % Пакет для підписів до зображень
\usepackage{hyperref} % Пакет для создания кликабельных ссылок
\usepackage{float}
\usepackage{tabularx}
\usepackage{longtable}

\begin{document}	

    % Титульная страница
    \begin{titlepage}
        \centering
        \large
        Київський нацiональний унiверситет iменi Тараса Шевченка\\
        Факультет комп’ютерних наук та кiбернетики\\
        Кафедра математичної інформатики\\
        
        \vspace*{4cm}
        
        \huge Курсова робота на тему: \\
            \textbf{Розробка методики порівняння ефективності алгоритмів патерн-метчингу}
        
        \vspace{4cm}
        
        \raggedleft
        \large
        \begin{tabular}{r}
            Виконав студент 3 курсу \\
            Гришечкін Тихон Сергійович \\
            \\
            Науковий керівник: \\
            доцент, доктор фізико-математичних наук Завадський І.О \\
        \end{tabular}
        
        \vfill
        
        \centering
        \large
        Київ, 2024
        
    \end{titlepage}
    
    % Оглавление
    \tableofcontents
    \newpage
    
    % Вступ
    \section{Вступ}

	Задача пошуку рядку є важливою задачею в інформатиці. Вона має широке застосування в різних областях, зокрема:

\begin{itemize}
    \item Інформаційний пошук: Алгоритми пошуку рядків використовуються в пошукових системах для
	знаходження релевантних документів на основі запитів користувачів.
    \item Біоінформатика: Пошук підрядків є ключовим у знаходженні послідовностей нуклеотидів або амінокислот у геномах та протеомах. \cite{dna}
    \item Обробка текстів: Алгоритми пошуку використовуються для знаходження та заміни текстових фрагментів у текстових редакторах.
    \item Бази даних: Пошук підрядків використовується в базах даних для виконання запитів зі згадками текстових фрагментів або шаблонів.
    \item Компіляція: Компілятори використовують алгоритми пошуку підрядків для аналізу та оптимізації програмного коду.

\end{itemize}

Тому важливою задачею є оцінка ефективності цих алгоритмів. Оцінка ефективності дозволяє визначити, який з алгоритмів найкраще підходить для конкретних умов та обмежень. У даній курсовій роботі ми запропонуємо методику порівняння ефективності різних алгоритмів пошуку рядку. Ми проведемо експериментальне дослідження на основі ряду критеріїв, таких як швидкість виконання, та стійкість до різних типів вхідних даних.

Результати даного дослідження можуть бути корисними для вибору оптимального алгоритму в залежності від конкретної задачі та умов її виконання.


    \newpage



    % Основна частина
    \section{Алгоритми пошуку рядка}

	\subsection{Постановка задачі патерн-метчингу}

	Нехай дані дві послідовності: текст \( T \) та патерн \( P \) (далі також інколи позначається, як <<шаблон>>), де \( |T| = n \) та \( |P| = m \). Задача полягає у знаходженні всіх входжень патерна \( P \) у текст \( T \).

При цьому передбачається, що:
\begin{itemize}
    \item \( T \) та \( P \) складаються з символів алфавіту \( \Sigma \).
    \item Алфавіт \( \Sigma \) може бути скінченним або нескінченним, але у нашій постановці розглядається скінченний алфавіт.
\end{itemize}


Розглядається задача пошуку підстроки у формулюванні \textbf{single-pattern matching}, що передбачає пошук одного заданого патерна в тексті. Не розглядаються задачі \textbf{approximate pattern searching}, де потрібно знаходити патерни з певною степенню схожості, або \textbf{regular pattern searching}, де патерн може бути виражений у вигляді регулярного виразу.


	\subsection{Загальна характеристика алгоритмів пошуку рядка}

	Найпростішим методом для пошуку підрядка в рядку є алгоритм повного перебору (brute force). Його суть полягає у перевірці кожної позиції в тексті \( T \) як можливої початкової позиції для патерна \( P \). Для кожної такої позиції перевіряється, чи співпадає патерн \( P \) з відповідною підстрокою в тексті \( T \). Цей метод має часову складність \( O(n \cdot m) \), де \( n \) – довжина тексту, а \( m \) – довжина патерна. Через високу обчислювальну складність цей алгоритм є дуже неоптимальним для великих текстів і патернів.

	У 1970 році Д. Морріс та В. Пратт \cite{morris-pratt} розробили перший оптимальний алгоритм пошуку підстроки – алгоритм Кнута-Морріса-Пратта (KMP). Цей алгоритм значно покращив ефективність пошуку, зменшивши часову складність до \( O(n + m) \).

	З часом з'явилося багато інших алгоритмів (більше 124 див. \cite{smart}). Всі ці алгоритми можна умовно поділити на чотири основні категорії:
	\begin{itemize}
		\item алгоритми на основі порівняння символів
		\item  алгоритми на основі суфіксних автоматів
		\item алгоритми на основі побітового паралелізму
		\item гібридні алгоритми.
	\end{itemize}

\textbf{Алгоритми на основі порівняння символів}

Алгоритми на основі порівняння символів (character-based approaches або comparison based approaches) є класичним підходом, який просто порівнює символи для вирішення задач пошуку рядка.

Алгоритми на основі порівняння символів мають дві основні стадії: пошук і зсув. Алгоритм Бойера-Мура \cite{bm}, є стандартним та еталонним методом цього типу. Він використовує таблицю зсувів для пропуску непотрібних порівнянь, що значно підвищує швидкість пошуку.

\textbf{Алгоритми на основі суфіксних автоматів}

Суфіксний автомат (Suffix automaton) складається з детермінованого ациклічного кінцевого автомата та суфіксного автомата, які разом дозволяють ефективно здійснювати пошук рядка.

Цей метод використовує спрямований ациклічний граф, де вершини є станами, а ребра – переходами між станами. Суфіксний автомат розпізнає всі суфікси патерна і дозволяє швидко знаходити підрядки.
Прикладом алгоритму даного класу є є Backward-DAWG-Matching алгоритм (BDM).

\textbf{Алгоритми на основі побітового паралелізму}

Алгоритми на основі паралелізму бітового рівня були запропоновані для прискорення процесу пошуку шляхом використання внутрішнього паралелізму бітових операцій, що зменшує кількість операцій у рази до $\omega$, де $\omega$ –  кількость бітів у машинному слові.

Ці алгоритми є швидкими та ефективними, особливо коли довжина патерна менша за довжину машинного слова. До таких алгоритмів належать наприклад Shift-OR (SO), Shift-AND (SA) алгоритми.

\textbf{Гібридні алгоритми}

Гібридні алгоритми комбінують переваги різних методів для вирішення складних задач. Вони поєднують методи з різних категорій для досягнення кращої ефективності.

Таким чином, за роки розвитку цієї області задач з'явилося багато алгоритмів для пошуку підрядка, які можна класифікувати за чотирма основними категоріями. Кожен клас алгоритмів має свої недоліки та переваги, які важливо розуміти при виборі оптимального алгоритму для своєї задачі.

\subsection{Алгоритм Бойера-Мура}
Розглянемо детальніше деякі алгоритми пошуку.

Першим розглянемо алгоритм Бойера-Мура (BM), який є класичним представником класу <<character-based>> алгоритмів.

Алгоритм шукає входження патерну $\textbf{p}$, прикладаючи його до тексту $\textbf{t}$ зліва направо, але при цьому порівняння, виконуються справа наліво, починаючи з останнього символу патерну.

Далі якщо при порівнянні знайдено перший неспівпадаючий символ патерну, то виконується зсув патерну на деяку кількість позицій, за допомогою наступних евристик:

\begin{itemize}
	\item \textit{Евристика стоп символів}:
	
	Для цього для кожного символу алфавіту $\Sigma$ запам'ятовуємо індекс останнього його входження в патерн, якщо він є, або запам'ятовуємо -1, якщо він не входить в патерн (вважаємо, що індексація символів починається з нуля). 
	Назвемо цей масив індексів $StopTable$.
	
	Тепер розглянемо символ тексту $c$, що не співпав на поточній ітерації порівняння. Позначимо поточний індекс патерну на якому відбулось неспівпадіння як $i$.
	Тоді якщо виконується \[i-StopTable[c] > 0\] то відбувається зсув патерну на $i-StopTable[c]$ кроків, інакше кажучи на найменшу кількість кроків щоб відбулось співпадіння з символом $c$. (рис. \ref{fig:boyer_moore})
	\item \textit{Евристика співпадаючого суфікса}:
	
	Якщо при порівнянні шаблону справа наліво збігся суфікс \( S \), а символ \( c \), що стоїть перед \( S \) в шаблоні не збігся (тобто шаблон має вигляд \( PcS \)),
 	то евристика співпадаючого суфікса зсуває шаблон на найменше число позицій вправо так, щоб рядок \( S \) збігся з шаблоном, а символ, що передує даному збігу \( S \) в шаблоні, відрізнявся б від \( c \).
	
	Заради цього для патерну $p$ перед початком пошуку, обраховуються відповідні величини зсуву, за допомогою алгоритму,
	схожого за ідеєю на алгоритми обчислення <<префікс-функції>> та <<Z-функції>>.

	Як і випадку цих алгоритмів ці зсуви обчислюються за $O(m)$ операцій.
	
	Далі в алгоритмі просто використовуються ці заздалегідь обчислені зсуви при неспівпадінні символів.

	Зазначимо, що якщо на кожній ітерації просто знову порівнювати символи, навіть з використанням зсувів асимптотика алгоритму
	складає $O(n*m)$ операцій. Для досягнення складності $O(n+m)$, треба не порівнювати з шаблоном вже співпадаючий суфікс, знайдений на попередній ітерації.

\end{itemize}
	\begin{figure}[h] % Починаємо середовище figure
		\centering % Центруємо малюнок
		\includegraphics[width=0.6\textwidth]{images/boyer_moore.png} % Вставляємо малюнок
		\caption{Приклад використання евристики стоп символів} % Підпис до малюнка
		\label{fig:boyer_moore} % Мітка для посилань на малюнок
	\end{figure}
	\begin{figure}[h] % Починаємо середовище figure
		\centering % Центруємо малюнок
		\includegraphics[width=0.6\textwidth]{images/boyer_moore_suffix.png} % Вставляємо малюнок
		\caption{Приклад використання евристики співпадаючого суфікса} % Підпис до малюнка
		\label{fig:boyer_moore_suffix} % Мітка для посилань на малюнок
	\end{figure}

    \newpage
	Додамо також, що існує багато модифікацій алгоритму Бойера-Мура, які використовують інші евристики або реалізують вже існуючі інакше.
	
	Прикладами таких алгоритмів є алгоритми Бойєра - Мура - Хорспула (BMH), Чжу - Такаокі (ZT), турбо - Бойера - Мура (TBM).

	Наприклад BMH використвує тільки <<евристику стоп символів>>, але тільки за останнім символом, тому є спрощени варіантом Бойера-Мура.

	ZT використовує також <<евристику стоп символів>>, але для пар символів, заради оптимізації при маленьких алфавітах.

	Зазначимо також, що довгі патерни зазвичай дають довші зсуви, тому алгоритми класу <<порівняння символів>> добре працюють на таких патернах.
	\subsection{Алгоритми Shift-OR (SO) та Shift-AND (SA)}

	Розглянемо алгоритми Shift-OR (SO) та Shift-AND (SA), які є представниками класу алгоритмів основаних на паралелізмі бітових операцій.

	Опишемо SA алгоритм.

	Нехай маємо $i$-й символ тексту $t$. 

	Введемо матрицю $Mask$ (рис \ref{fig:shift_or}), де
	\[Mask[i][j] = 1,\text{якщо } t[i-j..i] = p[0..j]\]
	\[Mask[i][j] = 0,\text{якщо } t[i-j..i] \neq  p[0..j]\]

	Тоді маємо входження шаблону на $i$-му кроці, коли $Mask[i][m-1] = 1$.
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.6\textwidth]{images/sa_example.png}
		\caption{Приклад матриці $Mask$}
		\label{fig:shift_or}
	\end{figure}

	Але вичислення матриці $Mask$, на кожному кроці займає $O(m)$ операцій тому такий алгоритм нічим не краще <<Brute-Force>> алгоритму, і фактично ним і є.

	Тоді нехай маємо матрицю $pos$, де для символу $c$ маємо
	\[pos[c][j] = 1,\text{якщо } p[j]=c\]
	\[pos[c][j] = 0,\text{якщо } p[j] \neq c\]
	Можемо помітити наступну властивість. 
	$$Mask[i]=(Mask[i-1]<<1)\And pos[t[i]]$$

	Де $<<$ - операція побітового зсуву вліво.

	Тепер можемо в рамках реалізації замінити вектори $Mask[i]$ та $pos[c]$, на звичайні змінні, для яких всі операції будуть виконані $O(1)$, але отримаємо очевидне обмеження $m<\omega$, де $\omega$ - довжина машинного слова.

	Shift-or алгоритм аналогічний алгоритму Shift-and, де просто інвертовано вектори $Mask[i]$ та $pos[c]$, а операція $and$ замінюється на $or$. 
	А критерієм входження стає $Mask[i][m-1]=0$.

	Алгоритми, що основані на паралелізмі бітових операцій називаються так бо на кожному кроці виконується $\omega$ паралельних порівнянь, хоча фактично виконується лише декілька бітових операцій.

	Такі алгоритми дають значне прискорення на патернах невеликої довжини, для яких вони і були створені. Для $m>\omega$, зазвичай ці алгоритми оптимізують або об'єднують з іншими.

	Наприклад у SA, для патернів більшої довжини, при знаходженні співпадіння довжини $\omega$ решту символів просто перевіряють до першого неспівпадіння.

	Також перевагою цих алгоритмів є те, що вони легко модифікуються до <<наближеного пошуку входження рядка>> (approximate pattern searching).
	Ці алгоритми вбудовані у реалізацію Unix утиліти \textit{agrep}, що і виконує цей наближений пошук.
    
	\subsection{Алгоритм Forward Dawg Matching}
Розглянемо також алгоритм Forward Dawg Matching (FDM), що є представником класу <<automata-based>> алгоритмів.

Алгоритм Forward Dawg Matching обчислює найдовший підрядок шаблону, що закінчується на кожній позиції в тексті.

Це можливо завдяки використанню найменшого суфіксного автомата (також називається DAWG, Directed Acyclic Word Graph) для шаблону. Найменший суфіксний автомат слова \( w \) - це детермінований кінцевий автомат \( S(w) = (Q, q_0, T, E) \). Мова, прийнята \( S(w) \), це \( L(S(w)) = \{u \in \Sigma^* : \exists v \in \Sigma^* \text{ така, що } w = vu\} \).

Підготовча фаза алгоритму Forward Dawg Matching полягає в обчисленні найменшого суфіксного автомата для шаблону \( x \). Це займає лінійний час та простір додаткової пам'яті відносно довжини шаблону.

Під час фази пошуку алгоритм Forward Dawg Matching аналізує символи тексту зліва направо за допомогою автомата \( S(x) \), починаючи з початкового стану \( q_0 \). Для кожного стану \( q \) у \( S(x) \) найдовший шлях від \( q_0 \) до \( q \) позначається як \( \text{length}(q) \).

Структура автомата використовує поняття суфіксних посилань. Для кожного стану \( q \) суфіксне посилання \( q \) позначається як \( S[q] \).

S[q] - посилання на стан автомата, що є найбільшим суфіксом стану q.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{images/suffix_automata.png}
	\caption{Приклад суфіксного автомата рядка "abcbc", з його суфіксними посиланнями}
	\label{fig:fdm}
\end{figure}

Для стану \( p \) нехай \( \text{Path}(p) = (p_0, p_1, \ldots, p_{\ell}) \) буде суфіксним шляхом \( p \), таким чином що \( p_0 = p \), для \( 1 \leq i \leq \ell \), \( p_i = S[p_{i-1}] \) і \( p_{\ell} = q_0 \).

Для кожного символу тексту \( t[j] \) послідовно, нехай \( p \) буде поточним станом, тоді алгоритм Forward Dawg Matching здійснює перехід, по символу \( t[j] \) для першого стану \( \text{Path}(p) \), для якого такий перехід визначений. Поточний стан \( p \) оновлюється за допомогою цільового стану цього переходу або початкового стану \( q_0 \), якщо не існує переходу по символу \( t[j] \) з будь-якого стану \( \text{Path}(p) \).

Збіг шаблону \( x \) знайдено, коли \( \text{length}(p) = m \), де $m =|x|$.

Недоліками алгоритмів, що основані на суфіксних автоматах є додаткові витрати на побудову автомата.

Перевагами таких алгоритмів є те що, їх можна реалізувати так, щоб співпадіння на кожному новому індексі тексту була знайдена  простими переходами по автомату, за $O(1)$ операцій, що підходить для так званих <<real-time-systems>>.

Також перевагою є те, що на кожному кроці алгоритм знаходить найбільший підрядок шаблону, що закінчується на поточній позиції тексту, а отже вирішує більш загальну задачу ніж пошук входжень патерна в текст.
% Практична частина
	\newpage
    \section{Порівняння ефективності алгоритмів}

	\subsection{Фактори впливу на ефективність алгоритмів}

	Одразу зазначимо, що не будемо порівнювати алгоритми за об'ємом зайнятої додаткової пам'яті, адже більшість алгоритмів займають $O(m)$, або $O(m*|\Sigma|)$ додаткової пам'яті, що є незначним показником при невеликих патернах та алфавітах на яких в більшості випадків виконують пошук.
	
	Також зазначимо, що в цій роботі не будуть порівнюватись алгоритми, що виконують препроцесинг над текстом (так звані <<offline exact string matching algorithms>>), адже їх потрібно порівнювати окремо від <<онлайн>> алгоритмів.

	Наведемо основні фактори впливу на швидкодію алгоритмів патерн метчингу:
	\begin{itemize}
		\item $|T|$ - довжина тексту.
		\item $|P|$ - довжина шаблону.
		\item $|\Sigma|$ - розмір алфавіту.
		\item Кількість різних підрядків $P$ та $T$.
		\item Кількість входжень $P$ в $T$.
		\item Граматика мови, до якої належить текст і шаблон (якщо існує).
		\item "Ворожість" користувача. Іншими словами: чи буде користувач навмисно задавати дані, на яких алгоритм повільно працюватиме?
		\item Архітектура процесора. Деякі процесори мають автоінкрементні або SIMD-операції, які дозволяють швидко порівняти дві ділянки ОЗП (наприклад, rep cmpsd x86). Деякі алгоритми використовують такі операції (SSE Filter Algorithm).
		\item Характер даних шаблона $P$ у порівнянні з $T$. Наприклад якщо $P$ - деяке число, що шукається в англійському тексті, то більшість $character-based$ алгоритмів оптимізує пошук використовуючи свої евристики зсуву. 
	\end{itemize}

	Додамо що цей перелік не є кінцевим і можна навести ще багато інших факторів впливу.

	\subsection{Методика порівняння алгоритмів}\label{methodic}

	У праці Ф. Саймона та Л. Тьєррі \cite{experiment} та інших роботах з порівнянням алгоритмів патерн-метчингу, при порівнянні алгоритмів пошуку, увагу було зосереджено на великій кількості алгоритмів та різних можливих вхідних текстах.
	При тестуванні патерни завжди обирались випадковим чином із тексту.

	Тому у власній роботі, я вирішив розширити множину можливих патернів і порівняння будуть виконуватись по наступним типам патернів:
	\begin{itemize}
		\item Випадкові патерни, заданого алфавіту.
		\item Патерни випадковим чином, обрані із заданого тексту.
		\item Патерни, що часто зустрічаються в тексті. Наприклад для тексту англійської літератури було обрано патерни найбільш повторюваних слів англійської мови. Аналогічно для української - найбільш повторюваних слів української мови. Для json бази даних - деякі ключові слова та значення полів, що часто зустрічаються.
	\end {itemize}

	Також зазначу, що не було спроби визначити ефективність алгоритмів, за рядом експериментів, окрім як просумувати абсолютні значення часу виконання алгоритмів.

	Тому у власній роботі я вводжу поняття відносного результату роботи алгоритму $\sigma_{\text{алг}}$.

	Нехай ми порівнюємо деяку множину алгоритмів. Нехай деякий алгоритм відпрацював найшивдше з усіх за час $t_{\text{min}}$.

	Тоді відносний результат алгоритму, що відпрацював за час $t_{\text{алг}}$, дорівнює:
	$$\sigma_{\text{алг}} = \frac{t_{\text{алг}}-t_{\text{min}}}{t_{\text{min}}}$$
    
	Введення відносних результатів дозволяє зробити загальний аналіз результатів роботи алгоритмів за декількома експериментами.

	Наприклад маємо такі результати роботи алгоритмів (табл \ref{table:times}):
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			& \textbf{Алгоритм 1} & \textbf{Алгоритм 2} \\ 
			\hline
			\textbf{Тест 1} & 40 & 20 \\ 
			\hline
			\textbf{Тест 2} & 500 & 700 \\ 
			\hline
		\end{tabular}
		\caption{Абсолютні результати алгоритмів у мс}
		\label{table:times}
	\end{table}

	Тоді маємо наступні відносні результати роботи алгоритмів (табл \ref{table:relative_times}):
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			& \textbf{Алгоритм 1} & \textbf{Алгоритм 2} \\ 
			\hline
			\textbf{Тест 1} & 1 & 0 \\ 
			\hline
			\textbf{Тест 2} & 0 & 0.4 \\ 
			\hline
		\end{tabular}
		\caption{Відносні результати алгоритмів $\sigma$}
		\label{table:relative_times}
	\end{table}

	Сумарний час виконання 1 алгоритму - 540 мс. Сумарний середній відносний результат 0.5.

	Сумарний час виконання 2 алгоритму - 720 мс. Сумарний середній відносний результат 0.2.

	Маємо що 1-й алгоритм сумарно працював менше часу, а 2-й в середньому менше відхилявся від оптимального за тестом.

	Середній відносний результат може бути непоганою оцінкою роботи алгоритма за декількома тестами, хоча можливо можна обрати більш доцільну формулу для обчислення $\sigma_{\text{алг}}$.

	Далі я буду користуватись формулою наданою в цьому підрозділі.

	Додамо що в практичній частині для порівняння тести будуть проводитися на наступних текстах:

	\begin{itemize}
		\item Англійська література - <<The Lord of the Rings: The Fellowship of the Ring>>
		\item Українська література - <<Лісова пісня>>
		\item Випадкова послідовність геному.
		\item Json база даних.
		\item Велика веб сторінка (html).
		\item rand2 - випадковий рядок на алфавіті довжини 2
		\item rand32 - випадковий рядок на алфавіті довжини 32
		\item rand64 - випадковий рядок на алфавіті довжини 64
		\item Великий текст на мові програмування $c$.
	\end{itemize}
	\subsection{Набір алгоритмів для порівняння}

	Для порівняння ефективності на практиці мною було обрано наступні алгоритми (табл \ref{table:string_algorithms}):

	\begin{table}[H]
		\centering
		\small
		\begin{tabular}{|c|c|c|c|}
			\hline
			& \textbf{Повна назва} & \textbf{Рік розробки} & \textbf{Клас алгоритму} \\ 
			\hline
			\textbf{KR} & Karp-Rabin & 1987 & comparison \\ 
			\hline
			\textbf{KMP} & Knuth-Morris-Pratt & 1977 & comparison \\ 
			\hline
			\textbf{BNDMQ2} & BNDM with q-grams & 2009 & bit-parallelism \\ 
			\hline
			\textbf{BM} & Boyer-Moore & 1977 & comparison \\ 
			\hline
			\textbf{BXS} & BNDM with Extended Shifts &  2010 & bit-parallelism \\ 
			\hline
			\textbf{BOM} &  Backward-Oracle-Matching & 1999 & automata \\ 
			\hline
			\textbf{Skip} & Skip-Search  & 1998 & comparison \\ 
			\hline
			\textbf{Hash3} & Wu-Manber algorithm	 & 2007 & comparison \\ 
			\hline
			\textbf{FS} & Fast-Search &  2003 & comparison \\ 
			\hline
			\textbf{SSM} & Simple String Matching & 2015 & hybrid \\ 
			\hline
			\textbf{SBNDM} & Simplified BNDM & 2003 & bit-parallelism \\ 
			\hline
			\textbf{BSDM} & Backward SNR DAWGM & 2012 & automata \\ 
			\hline
		\end{tabular}
		\caption{Інформація про обрані алгоритми пошуку рядка}
		\label{table:string_algorithms}
	\end{table}

	При виборі набору алгоритмів орієнтувався на набір, що містиме деякі класичні алгоритми (\textbf{KR},\textbf{KMP},\textbf{BM}). Інші обирались серед більш сучасних, так щоб алгоритмів різних класів було представлено приблизно порівну.

	
	\newpage
	\section{Практична частина}
	
	\subsection{Порівняння алгоритмів на випадкових патернах}
	В цьому підрозділі будемо порівнювати алгоритми на повністю випадкових патернах, заданого алфавіту для кожного тесту. 

	\textbf{Середовище тестування:}

	Всі тестування проводились на персональному комп'ютері з наступними характеристиками:
	\begin{itemize}
		\item \textbf{Процесор:} Intel(R) Core(TM) i7-9750H CPU 2.60GHz
		\item \textbf{Оперативна пам'ять:} 16.0 GB
		\item \textbf{Жорсткий диск:} 512 GB SSD
		\item \textbf{Операційна система:} Windows 10 Home 64-bit
		\item \textbf{Графічний процесор:} NVIDIA GeForce GTX 1650 8GB
	\end{itemize}

	Проведемо тестування на англійському тексті (<<The Lord of the Rings: The Fellowship of the Ring>>, табл. \ref{table:lotr}), та випадкових патернах довжини m. $$m=2^k, (1<=k<=12)$$
	Додамо що, результат вказаний у табл. \ref{table:lotr} обраховувався не одним тестуванням, а для кожного $m$ проводилась константна кількість (в моєму випадку 30) раундів тестування, і сумарний час їх виконання для кожного алгоритму було записано у таблицю.

	\begin{table}[h]
		\centering
		\scriptsize
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		\textbf{m} & \textbf{KR} & \textbf{KMP} & \textbf{BNDMQ2} & \textbf{BM} & \textbf{BXS} & \textbf{BOM} & \textbf{Skip} & \textbf{Hash3} & \textbf{FS} & \textbf{SSM} & \textbf{SBNDM} & \textbf{BSDM} \\
		\hline
		2 & 148.09 & 232.28 & 157.14 & 187.87 & 60.26 & 225.18 & 57.41 & 232.22 & 154.28 & 138.43 & 198.38 & \textbf{49.66} \\
		\hline
		4 & 139.92 & 230.29 & 51.46 & 95.36 & 31.52 & 167.41 & 31.58 & 265.74 & 77.60 & 67.08 & 71.31 & \textbf{29.69} \\
		\hline
		8 & 129.49 & 226.57 & 22.05 & 46.34 & 14.96 & 136.70 & 15.57 & 90.37 & 38.90 & 33.42 & 30.36 & \textbf{13.64} \\
		\hline
		16 & 132.52 & 228.02 & 10.62 & 23.38 & 9.41 & 131.90 & 10.14 & 39.02 & 20.21 & 17.19 & 14.39 & \textbf{9.03} \\
		\hline
		32 & 135.19 & 226.09 & \textbf{5.97} & 12.66 & 6.36 & 125.83 & 7.05 & 18.99 & 11.07 & 9.46 & 7.47 & 7.23 \\
		\hline
		64 & 130.19 & 225.36 & 5.58 & 7.06 & \textbf{4.72} & 119.16 & 5.43 & 9.88 & 6.27 & 5.20 & 5.58 & 5.96 \\
		\hline
		128 & 134.70 & 225.72 & 5.46 & 4.60 & \textbf{3.64} & 93.22 & 4.97 & 5.97 & 4.37 & \textbf{3.64} & 5.63 & 6.00 \\
		\hline
		256 & 138.60 & 238.41 & 6.07 & 3.96 & 236.48 & 71.59 & 4.93 & 4.58 & 4.03 & \textbf{2.95} & 6.08 & 5.66 \\
		\hline
		512 & 130.37 & 223.59 & 5.47 & 3.63 & 225.89 & 46.16 & 4.74 & 4.26 & 3.71 & \textbf{2.73} & 6.29 & 5.64 \\
		\hline
		1024 & 134.62 & 227.50 & 5.93 & 3.69 & 226.83 & 41.15 & 5.86 & 4.01 & 4.09 & \textbf{3.03} & 6.33 & 6.09 \\
		\hline
		2048 & 129.63 & 228.63 & 5.53 & 3.89 & 228.88 & 54.92 & 7.95 & 4.23 & 4.43 & \textbf{3.61} & 5.83 & 6.18 \\
		\hline
		4096 & 135.46 & 229.16 & 5.76 & 5.36 & 229.06 & 104.23 & 14.62 & \textbf{5.27} & 5.99 & 5.51 & 6.95 & 6.77 \\
		\hline
		\end{tabular}
		\caption{Результати роботи алгоритмів на англійському тексті (час у мілісекундах)}
		\label{table:lotr}
		\end{table}

		Кожен найкращий результат за заданим $m$, виділено у таблиці жирним шрифтом. Зазначимо що результати тестуванням длі інших текстів, будуть виводитись аналогічним чином до табл. \ref{table:lotr} і протягом курсової роботи формат не змінюється.

		Проаналізуємо отримані результати. Бачимо, що SSM алгоритм отримує оптимальні результати на великих $m$, а BSDM та BXS - на невеликих.

		Бачимо що із класичних алгоритмів KR та KMP - показують дуже неоптимальні результати, а BM - результат близький до оптимального для великих $m$.

		Проведемо тестування на рядку rand32 (табл. \ref{table:rand32}).
		\begin{table}[h]
			\centering
			\scriptsize
			\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
			\hline
			\textbf{m} & \textbf{KR} & \textbf{KMP} & \textbf{BNDMQ2} & \textbf{BM} & \textbf{BXS} & \textbf{BOM} & \textbf{Skip} & \textbf{Hash3} & \textbf{FS} & \textbf{SSM} & \textbf{SBNDM} & \textbf{BSDM} \\
			\hline
			2 & 13.50 & 22.25 & 14.80 & 18.45 & 5.96 & 21.28 & 5.39 & 22.51 & 15.75 & 13.21 & 19.45 & \textbf{4.82} \\
			\hline
			4 & 12.89 & 22.12 & 5.03 & 9.21 & 2.99 & 16.27 & 2.96 & 26.00 & 8.12 & 6.78 & 7.01 & \textbf{2.69} \\
			\hline
			8 & 13.57 & 22.80 & 2.24 & 4.66 & 1.77 & 13.72 & 1.85 & 8.88 & 4.44 & 3.46 & 3.78 & \textbf{1.57} \\
			\hline
			16 & 13.26 & 22.67 & 1.15 & 2.51 & 1.06 & 13.16 & 1.26 & 3.94 & 2.53 & 1.83 & 1.44 & \textbf{0.96} \\
			\hline
			32 & 12.92 & 22.41 & \textbf{0.61} & 1.25 & 0.67 & 12.10 & 0.76 & 1.89 & 1.54 & 0.96 & 0.78 & 0.79 \\
			\hline
			64 & 13.25 & 22.24 & 0.61 & 0.74 & \textbf{0.50} & 13.07 & 0.81 & 1.00 & 1.12 & 0.58 & 0.64 & 0.74 \\
			\hline
			128 & 13.93 & 22.53 & 0.55 & 0.50 & \textbf{0.36} & 11.54 & 0.83 & 0.62 & 0.92 & 0.45 & 0.69 & 1.06 \\
			\hline
			256 & 21.89 & 31.19 & 1.07 & \textbf{0.54} & 36.67 & 17.27 & 1.60 & 0.76 & 0.99 & 0.62 & 0.89 & 0.94 \\
			\hline
			512 & 19.64 & 27.87 & 0.85 & 1.50 & 30.04 & 17.61 & 1.86 & \textbf{0.44} & 1.13 & 0.71 & 1.56 & 0.92 \\
			\hline
			1024 & 13.42 & 22.32 & 0.54 & 0.79 & 22.37 & 22.14 & 2.89 & \textbf{0.48} & 1.26 & 1.05 & 0.63 & 0.99 \\
			\hline
			2048 & 13.47 & 23.30 & \textbf{0.58} & 1.49 & 23.01 & 46.59 & 6.12 & 0.70 & 1.92 & 1.98 & 0.64 & 1.46 \\
			\hline
			4096 & 13.00 & 22.98 & \textbf{0.54} & 2.50 & 22.98 & 94.79 & 11.08 & 1.00 & 2.97 & 3.19 & 0.59 & 2.12 \\
			\hline
			\end{tabular}
			\caption{Результати роботи алгоритмів на rand32 (час у мс)}
			\label{table:rand32}
			\end{table}

			Отримуємо схожі результати, як у попередньому досліді, окрім того що SSM не показує найоптимальніших результатів на великих $m$. Замість нього накращі показники демонструють BNDMQ2 та Hash3 алгоритми.
			
			Тепер наведемо сумарні абсолютні результати (табл. \ref{table:absolute_fullrandom}) за тестуваннями на всіх обраних текстах (підрозділ \ref{methodic}) та середні сумарні відносні результати (табл. \ref{table:relative_fullrandom}).

			\begin{table}[h]
				\centering
				\scriptsize
				\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
				\hline
				\textbf{m} & \textbf{KR} & \textbf{KMP} & \textbf{BNDMQ2} & \textbf{BM} & \textbf{BXS} & \textbf{BOM} & \textbf{Skip} & \textbf{Hash3} & \textbf{FS} & \textbf{SSM} & \textbf{SBNDM} & \textbf{BSDM} \\
				\hline
				2 & 343.05 & 558.52 & 377.12 & 452.68 & 140.45 & 534.17 & 136.93 & 559.03 & 379.86 & 334.42 & 487.80 & \textbf{120.13} \\
				\hline
				4 & 337.24 & 560.69 & 128.51 & 233.96 & 77.33 & 410.51 & 76.45 & 653.19 & 192.68 & 164.83 & 177.10 & \textbf{69.19} \\
				\hline
				8 & 341.15 & 564.62 & 60.14 & 116.08 & 40.89 & 355.42 & 48.95 & 223.05 & 99.90 & 84.06 & 79.18 & \textbf{36.37} \\
				\hline
				16 & 327.74 & 557.20 & 26.62 & 58.96 & 24.33 & 323.72 & 25.93 & 95.88 & 53.45 & 42.77 & 36.02 & \textbf{23.52} \\
				\hline
				32 & 348.93 & 579.74 & \textbf{18.21} & 31.93 & 19.14 & 327.99 & 18.64 & 49.68 & 32.88 & 23.68 & 20.05 & 18.72 \\
				\hline
				64 & 325.00 & 557.51 & 13.80 & 17.75 & \textbf{11.87} & 299.33 & 14.91 & 24.82 & 19.47 & 13.50 & 14.86 & 15.36 \\
				\hline
				128 & 330.90 & 556.18 & 13.80 & 11.73 & \textbf{8.90} & 239.70 & 14.97 & 14.86 & 14.36 & 9.69 & 14.77 & 15.22 \\
				\hline
				256 & 359.48 & 606.94 & 15.95 & 10.22 & 608.19 & 207.74 & 17.47 & 13.27 & 14.59 & \textbf{9.00} & 15.89 & 15.12 \\
				\hline
				512 & 346.30 & 576.77 & 14.66 & 10.93 & 583.08 & 186.68 & 23.49 & 10.52 & 14.17 & \textbf{10.16} & 16.52 & 15.61 \\
				\hline
				1024 & 340.94 & 569.07 & 14.68 & 12.59 & 571.17 & 248.32 & 35.56 & \textbf{10.68} & 16.77 & 13.70 & 15.84 & 17.67 \\
				\hline
				2048 & 335.24 & 573.32 & 14.18 & 17.44 & 572.96 & 437.19 & 60.05 & \textbf{12.21} & 21.79 & 20.61 & 15.25 & 21.32 \\
				\hline
				4096 & 348.26 & 581.89 & \textbf{14.34} & 28.35 & 584.24 & 911.85 & 110.31 & 16.47 & 32.92 & 33.86 & 16.36 & 28.86 \\
				\hline
				\end{tabular}
				\caption{Сумарні абсолютні результати алгоритмів (час у мілісекундах)}
				\label{table:absolute_fullrandom}
				\end{table}

				\begin{table}[H]
					\centering
					\scriptsize
					\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
					\hline
					\textbf{m} & \textbf{KR} & \textbf{KMP} & \textbf{BNDMQ2} & \textbf{BM} & \textbf{BXS} & \textbf{BOM} & \textbf{Skip} & \textbf{Hash3} & \textbf{FS} & \textbf{SSM} & \textbf{SBNDM} & \textbf{BSDM} \\
					\hline
					2 & 1.80 & 3.62 & 2.13 & 2.76 & 0.15 & 3.41 & 0.13 & 3.64 & 2.20 & 1.77 & 3.10 & \textbf{0.00} \\
					\hline
					4 & 3.96 & 7.27 & 0.91 & 2.44 & 0.14 & 5.06 & 0.12 & 8.68 & 1.90 & 1.45 & 1.64 & \textbf{0.00} \\
					\hline
					8 & 8.32 & 14.46 & 0.63 & 2.16 & 0.13 & 8.68 & 0.34 & 5.11 & 1.84 & 1.31 & 1.19 & \textbf{0.00} \\
					\hline
					16 & 12.60 & 22.11 & 0.11 & 1.49 & 0.04 & 12.33 & 0.11 & 2.98 & 1.35 & 0.78 & 0.50 & \textbf{0.00} \\
					\hline
					32 & 23.49 & 40.46 & \textbf{0.18} & 1.29 & 0.27 & 22.00 & 0.32 & 2.53 & 1.58 & 0.72 & 0.41 & 0.33 \\
					\hline
					64 & 27.46 & 47.85 & 0.21 & 0.56 & \textbf{0.00} & 25.77 & 0.36 & 1.17 & 1.03 & 0.21 & 0.33 & 0.37 \\
					\hline
					128 & 39.28 & 67.02 & 0.69 & 0.49 & \textbf{0.00} & 30.01 & 1.13 & 0.84 & 1.29 & 0.29 & 0.84 & 0.98 \\
					\hline
					256 & 36.23 & 60.98 & 0.65 & 0.09 & 61.98 & 22.58 & 1.19 & 0.37 & 0.80 & \textbf{0.06} & 0.69 & 0.62 \\
					\hline
					512 & 37.15 & 61.82 & 0.60 & 0.42 & 62.98 & 25.32 & 2.57 & \textbf{0.11} & 0.95 & 0.36 & 0.88 & 0.80 \\
					\hline
					1024 & 31.19 & 52.37 & 0.35 & 0.46 & 52.91 & 33.05 & 3.80 & \textbf{0.05} & 1.09 & 0.74 & 0.48 & 0.83 \\
					\hline
					2048 & 25.93 & 44.58 & 0.15 & 0.90 & 44.43 & 52.62 & 6.29 & \textbf{0.09} & 1.43 & 1.38 & 0.24 & 1.04 \\
					\hline
					4096 & 23.57 & 40.56 & \textbf{0.01} & 2.12 & 40.83 & 109.98 & 12.16 & 0.44 & 2.68 & 2.88 & 0.12 & 1.86 \\
					\hline
					\end{tabular}
					\caption{Середні сумарні відносні результати }
					\label{table:relative_fullrandom}
					\end{table}

					Бачимо що найоптимальніші алгоритми за абсолютними та відносними показниками співпадають, окрім випадку m = 512.
					За абсолютним показником найкращим алгоритмом для m=512, є SSM, а за відносним - Hash3.
					Для інших m - бачимо, що для найменшим m - найоптимальнішим алгоритмом є BSDM, для середніх - BXS, а для великих - Hash3, SSM та BNDMQ2.

					Для наочності додамо апроксимовані графіки залежності часу виконання кожного алгоритму (рис. \ref{fig:full_random_graph}) від довжини патерну (за абсолютним показником).

					\begin{figure}[h]
						\centering
						\includegraphics[width=1\textwidth]{images/full_random_graph.png}
						\caption{Залежність часу виконання алгоритмів від довжини патерну}
						\label{fig:full_random_graph}
					\end{figure}
					% Висновки
	\newpage
    \section{Висновки}

    \newpage
    
    % Список літератури
    \begin{thebibliography}{9}
        \addcontentsline{toc}{section}{Література} % Добавление списка литературы в оглавление
		\bibitem{dna}
		Alsmadi, I., \& Nuser, M. (2012). String matching evaluation methods for DNA comparison. International Journal of Advanced Science and Technology, 47(1), 13-32.
		\bibitem{morris-pratt}
		J. H. Morris, Jr and V. R. Pratt. A linear pattern-matching algorithm. Report 40, University of California, Berkeley, 1970.
		\bibitem{smart}
		Faro, S., \& Lecroq, T., Borzi, S., Di Mauro, S.,\& Maggio, A. (2016, August). The String Matching Algorithms Research Tool. In Stringology (pp. 99-111).
		\bibitem{exact}
		Faro, S., \& Lecroq, T. (2013). The exact online string matching problem: A review of the most recent results. ACM Computing Surveys (CSUR), 45(2), 1-42.
		\bibitem{bm}
		R. S. Boyer and J. S. Moore. A fast string searching algorithm. Commun.
ACM, 20(10):762–772, 1977.
		\bibitem{experiment}
		Faro, S., \& Lecroq, T. (2010). The exact string matching problem:
		
		a comprehensive experimental evaluation. arXiv preprint arXiv:1012.2547.
    \end{thebibliography}
    
\end{document}